# SP1 Prover Production Optimization Guide (Local Proving Only)

This guide outlines strategies to dramatically improve proving performance in production for the Diem ZKP prover **without using external prover networks** (all proving done locally for data privacy).

## Current Performance (Baseline)

**Test Results (CPU-only, local):**
- ProverClient init: ~38 seconds (first time)
- Core proof generation: ~70 seconds
- Compressed proof: **Hours** (20+ GB RAM)

## Production Optimization Strategies

### 1. GPU Acceleration (CUDA) - 10-100x Faster ‚ö°

**Performance Improvement:**
- **10x faster** than CPU for most workloads
- **100x faster** with specialized ASIC hardware (Cysic)
- **6.4x speedup** for compute-heavy programs (SP1 Turbo benchmarks)

**Hardware Requirements:**
- NVIDIA GPU with **24GB+ VRAM**
- Compute Capability **8.6 or higher**
- Minimum 4 CPU cores with 16GB RAM
- Recommended: NVIDIA A100, A6000, or H100

**Setup:**

```bash
# Install CUDA 12
# Download from: https://developer.nvidia.com/cuda-downloads

# Install CUDA Container Toolkit (for Docker)
# https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html
```

**Code Changes:**

```rust
// Option 1: Environment variable
// Set SP1_PROVER=cuda in .env
let prover = ProverClient::from_env();

// Option 2: Explicit configuration
let prover = ProverClient::builder()
    .cuda()
    .build();

// IMPORTANT: Wrap in Arc<Mutex<>> for thread safety
// CUDA prover is single-threaded and cannot be initialized twice
use std::sync::{Arc, Mutex};
let prover = Arc::new(Mutex::new(prover));
```

**Expected Performance:**
- Core proofs: ~7 seconds (vs 70s on CPU)
- Compressed proofs: ~10-15 minutes (vs hours on CPU)

---

### 2. Succinct Prover Network - Unlimited Scale üåê

**Performance Improvement:**
- **Distributed proving** across many GPUs in parallel
- Proves Ethereum mainnet blocks in **< 40 seconds**
- **10x cheaper** than running your own infrastructure

**How It Works:**
- Send proof requests to Succinct's decentralized network
- Network assigns to lowest bidder (reverse auction)
- Proofs generated on high-end GPU clusters

**Setup:**

```bash
# 1. Get API key from https://platform.succinct.xyz/
# 2. Set environment variables in .env
SP1_PROVER=network
SP1_PRIVATE_KEY=your_private_key_here  # Secp256k1 keypair
```

**Code (No Changes Required!):**

```rust
// Same code as before - just set environment variables
let prover = ProverClient::from_env();

// Proofs will be generated on the network
let proof = prover.prove(&pk, stdin).compressed().run()?;
```

**Pricing:**
- Market-driven auction pricing
- ~$0.001 per transaction (for average Ethereum blocks)
- **10x cheaper** than other zkVMs
- Pay with $PROVE tokens

**Network Details:**
- Mainnet: `https://rpc.mainnet.succinct.xyz`
- Supports 35+ leading protocols
- 5M+ proofs generated to date
- Used by Polygon, Mantle, Celestia, Lido

---

### 3. Proof Type Selection - Trade Speed vs Size ‚öñÔ∏è

Different proof types have different performance characteristics:

| Proof Type | Speed | Size | On-chain Cost | Use Case |
|------------|-------|------|---------------|----------|
| **Core** | ‚ö°‚ö°‚ö° Fast (~70s CPU) | ~100KB+ | Cannot verify | Testing only |
| **Compressed** | üêå Slow (hours CPU) | ~1-2KB | Medium | Good balance |
| **Plonk** | üêåüêå Very slow | ~300B | High | On-chain verification |
| **Groth16** | üêåüêå Very slow | ~200B | Low | Optimized on-chain |

**Recommendation for Production:**

```rust
// For testing/development: Core mode
let proof = prover.prove(&pk, stdin).run()?;

// For production (with GPU or network): Compressed mode
let proof = prover.prove(&pk, stdin).compressed().run()?;

// For on-chain verification: Groth16 (lowest gas)
let proof = prover.prove(&pk, stdin).groth16().run()?;
```

---

### 4. Batch Processing - Amortize Costs üì¶

**Strategy:**
Batch multiple state updates into a single proof to amortize proving costs.

**Benefits:**
- 10 updates batched: ~28K gas per update (vs 250K single)
- 100 updates batched: ~4K gas per update

**Implementation:**

```rust
// Instead of proving each state transition individually
// Batch multiple transitions into the guest program

pub struct BatchedStateProofs {
    pub proofs: Vec<AptosStateProof>,
}

// Guest program verifies all proofs in batch
sp1_zkvm::io::read::<BatchedStateProofs>();
for proof in proofs.iter() {
    verify_state_transition(proof);
}
```

---

### 5. Recommended Production Architecture üèóÔ∏è

**Development Environment:**
```
ProverClient (CPU mode)
‚îî‚îÄ‚îÄ Core proofs for quick testing (~2 minutes)
```

**Staging Environment:**
```
ProverClient (CUDA on AWS g6.2xlarge)
‚îî‚îÄ‚îÄ Compressed proofs for integration testing (~15 minutes)
```

**Production Environment (Option A - Self-hosted):**
```
ProverClient (CUDA on AWS g6.16xlarge or Lambda A100)
‚îú‚îÄ‚îÄ Multiple GPU instances for parallel proving
‚îú‚îÄ‚îÄ Load balancer distributing proof requests
‚îî‚îÄ‚îÄ Compressed proofs (~5-10 minutes per proof)
```

**Production Environment (Option B - Network):**
```
ProverClient (network mode)
‚îú‚îÄ‚îÄ Set SP1_PROVER=network
‚îú‚îÄ‚îÄ Succinct Network handles distribution
‚îî‚îÄ‚îÄ Compressed proofs (< 1 minute with parallel GPUs)
```

---

## Implementation Roadmap

### Phase 1: Enable GPU Acceleration (Week 1)
- [ ] Provision GPU instance (AWS g6.xlarge or Lambda A6000)
- [ ] Install CUDA 12 and dependencies
- [ ] Update code to use `ProverClient::builder().cuda().build()`
- [ ] Test compressed proof generation (~15 min vs hours)

### Phase 2: Network Integration (Week 2)
- [ ] Sign up for Succinct Platform (https://platform.succinct.xyz/)
- [ ] Get API key and set `SP1_PROVER=network`
- [ ] Test proof generation on network
- [ ] Benchmark costs and latency

### Phase 3: Production Deployment (Week 3-4)
- [ ] Choose architecture (self-hosted GPU vs network)
- [ ] Implement batch processing for multiple state updates
- [ ] Set up monitoring and alerting
- [ ] Deploy to production

---

## Cost Analysis

### Option 1: Self-Hosted GPU

**Hardware:**
- AWS g6.xlarge: $1.01/hour (1x NVIDIA L4, 24GB)
- AWS g6.16xlarge: $8.14/hour (4x NVIDIA L4, 96GB total)
- Lambda A100: $1.10/hour (spot pricing)

**Assumptions:**
- 1 compressed proof every 15 minutes = 4 proofs/hour
- Running 24/7 with 50% utilization

**Monthly Cost:**
- g6.xlarge: ~$365/month (96 proofs/day)
- Lambda A100: ~$400/month (96 proofs/day, faster)

### Option 2: Succinct Prover Network

**Pricing:**
- ~$0.001 per proof (Ethereum block size)
- Market-driven auction (can be lower)

**Monthly Cost:**
- 96 proofs/day √ó 30 days = 2,880 proofs
- 2,880 √ó $0.001 = **~$3/month**

**Winner: Network is ~100x cheaper for low-medium volume**

Break-even point: ~10,000 proofs/month (continuous high-volume operation)

---

## Quick Start: Enable Network Mode

**1. Update .env file:**

```bash
# Add to .env
SP1_PROVER=network
SP1_PRIVATE_KEY=0xYOUR_PRIVATE_KEY_HERE
```

**2. No code changes needed:**

Your existing code will automatically use the network:

```rust
let prover = ProverClient::new();  // Reads SP1_PROVER from env
let proof = prover.prove(&pk, stdin).compressed().run()?;
```

**3. Test it:**

```bash
cargo run --release --bin prover
```

That's it! Proofs will now be generated on Succinct's network.

---

## Performance Comparison Table

| Configuration | Init Time | Core Proof | Compressed Proof | Cost/Proof | Scalability |
|--------------|-----------|------------|------------------|------------|-------------|
| **Current (CPU)** | 38s | 70s | Hours | Free | Poor |
| **GPU (CUDA)** | 38s | ~7s | 10-15 min | $0.25 | Medium |
| **Network (Many GPUs)** | 38s | N/A | < 1 min | $0.001 | Unlimited |

---

## Monitoring and Metrics

Track these metrics in production:

```rust
// Add timing instrumentation
let start = std::time::Instant::now();
let proof = prover.prove(&pk, stdin).compressed().run()?;
let duration = start.elapsed();

// Log metrics
tracing::info!(
    duration_secs = duration.as_secs(),
    proof_size_bytes = proof.bytes().len(),
    mode = "compressed",
    "Proof generated successfully"
);
```

**Key Metrics:**
- Average proof generation time
- P95/P99 latency
- Cost per proof
- Success/failure rate
- Queue depth (if batching)

---

## Troubleshooting

### CUDA Out of Memory
```
Error: CUDA out of memory
```
**Solution:** Use larger GPU (A100 with 80GB) or reduce proof complexity

### Network Timeout
```
Error: Proof request timed out
```
**Solution:** Increase timeout or check network status at https://status.succinct.xyz

### Initialization Slow
```
ProverClient::new() taking 30+ seconds
```
**Expected:** First-time initialization downloads prover parameters (~266MB)
**Solution:** This is cached in `~/.sp1/` after first run

---

## Next Steps

1. **Immediate (This Week):** Set up network mode for 100x speedup at minimal cost
2. **Short-term (Next Month):** Provision GPU instance for testing
3. **Long-term (Next Quarter):** Implement batching and optimize guest program

For questions, see:
- SP1 Documentation: https://docs.succinct.xyz
- Succinct Discord: https://discord.gg/succinct
- GitHub Issues: https://github.com/succinctlabs/sp1/issues
